{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['localhost', 'otherhost'],\n",
    "    http_auth=('elastic', 'changeme'),\n",
    "    port=9200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputFile = \"/home/foodmap/food-tweets-2017-04-23.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cities with all name:  22309\n",
      "All cities unique geonameid:   23516\n",
      "All countries with all names:  24782\n",
      "All countries unique geonameid:   251\n",
      "Len of country code dict 251\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "os.chdir(\"/home/foodmap/food101/\")\n",
    "sys.path.append(os.getcwd())\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from processing.preprocess_tweet import process_tweet\n",
    "from processing.twitter.Tweet import Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweetsAsDict = Tweet.getTweetAsDictionary(inputFile)\n",
    "i = 0\n",
    "numIndex = 0\n",
    "for tweet in tweetsAsDict:\n",
    "    \n",
    "    i += 1\n",
    "    if i % 10000 == 0:\n",
    "        print \"Processed tweets: \", i\n",
    "        print \"Indexed tweets: \", numIndex\n",
    "\n",
    "    new_tweet = process_tweet(tweet, forStream=False)\n",
    "    if new_tweet is None:\n",
    "        continue\n",
    "    # new_tweet_id = new_tweet[\"id\"]\n",
    "#     print tweet\n",
    "#     print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
    "#     print new_tweet\n",
    "    \n",
    "    # check len of img_categ\n",
    "    if new_tweet[\"img_categories\"] is not None and len(new_tweet[\"img_categories\"]) > 0:\n",
    "        new_tweet[\"img_category\"] = new_tweet[\"img_categories\"][0][\"label\"]\n",
    "        new_tweet[\"img_category_score\"] = new_tweet[\"img_categories\"][0][\"score\"]\n",
    "    else:\n",
    "        new_tweet[\"img_category\"] = None\n",
    "        new_tweet[\"img_category_score\"] = 0.0\n",
    "\n",
    "    # check len of text_categ\n",
    "    if len(new_tweet[\"text_categories\"]) != 0:\n",
    "        print new_tweet[\"text_categories\"]\n",
    "        for cat in new_tweet[\"text_categories\"]:\n",
    "            new_tweet[\"text_category\"] = cat\n",
    "            print \"Has text categories\" \n",
    "            print \"Id: \", numIndex\n",
    "            print \"--------------------------\"\n",
    "\n",
    "            # split index per month\n",
    "            es.index(index=\"trends04\", doc_type='tweet', id=numIndex, body=new_tweet)\n",
    "            numIndex += 1\n",
    "    else:\n",
    "        new_tweet[\"text_category\"] = None\n",
    "        # split index per month\n",
    "        print \"Doesn't have text categories\" \n",
    "        print \"Id: \", numIndex\n",
    "        print \"--------------------------\"\n",
    "        es.index(index=\"trends04\", doc_type='tweet', id=numIndex, body=new_tweet)\n",
    "        numIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'batches': 15,\n",
       " u'deleted': 14950,\n",
       " u'failures': [],\n",
       " u'noops': 0,\n",
       " u'requests_per_second': -1.0,\n",
       " u'retries': {u'bulk': 0, u'search': 0},\n",
       " u'throttled_millis': 0,\n",
       " u'throttled_until_millis': 0,\n",
       " u'timed_out': False,\n",
       " u'took': 240,\n",
       " u'total': 14950,\n",
       " u'version_conflicts': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.delete_by_query(index='trends04', doc_type='tweet', body={\n",
    "    'query': {\n",
    "        \"match_all\" : {}\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es.count(index='trends04', doc_type='tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search tweet text for QUERY\n",
    "es.search(index=\"trends\", body={\"query\": {\"match\": {'tweet_body.text':'lasagna'}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search tweet for ID\n",
    "es.get(index='trends', doc_type='tweet', id=855919564705673216)\n",
    "# http://foodmap.isti.cnr.it:9200/trends/tweet/856023708892360704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dealing with the index \n",
    "r = requests.get('http://foodmap.isti.cnr.it:9200/',  auth=('elastic', 'changeme'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
